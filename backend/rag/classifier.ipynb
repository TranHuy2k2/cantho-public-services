{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 15:04:24.195415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-08 15:04:24.195459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-08 15:04:24.196898: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-08 15:04:24.204339: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 15:04:25.069684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tranhuy/Desktop/Project/cantho-public-services/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 15:06:24.298256: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 196611072 exceeds 10% of free system memory.\n",
      "2024-01-08 15:06:24.454889: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 196611072 exceeds 10% of free system memory.\n",
      "2024-01-08 15:06:24.509614: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 196611072 exceeds 10% of free system memory.\n",
      "2024-01-08 15:06:25.919503: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 196611072 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "vocab.txt: 100%|██████████| 895k/895k [00:01<00:00, 629kB/s]\n",
      "bpe.codes: 100%|██████████| 1.14M/1.14M [00:00<00:00, 1.27MB/s]\n",
      "tokenizer.json: 100%|██████████| 3.13M/3.13M [00:01<00:00, 1.58MB/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = TFAutoModel.from_pretrained(\"vinai/phobert-base-v2\", from_pt=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForClassification(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.bert.trainable = False\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.bert(inputs)[1]\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 15:09:05.312768: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 196611072 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    classifier = BERTForClassification(model, num_classes=2)\n",
    "    classifier.load_weights('./model/model1/model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"context: Thủ tục hành chính tên Cấp lại giấy chứng sinh đối với trường hợp bị mất hoặc hư hỏng với mã 1.002150.000.00.00.H13 được thực hiện theo trình tự thực hiện như sau \\nquestion: đăng ký giấy cấp lại căn cước công dân cần hồ sơ gì?\"\n",
    "tokenized_text = tokenizer([text], return_tensors=\"tf\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.26601812, 0.7339819 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    output = classifier.call(tokenized_text)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
