{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tranhuy/Desktop/Project/cantho-public-services'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(\"../../\"))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tranhuy/Desktop/Project/cantho-public-services/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tranhuy/Desktop/Project/cantho-public-services/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/tranhuy/Desktop/Project/cantho-public-services/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/tranhuy/Desktop/Project/cantho-public-services/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2024-05-05 23:55:42.213829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 23:55:42.213864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 23:55:42.215364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 23:55:42.221480: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 23:55:43.150272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tranhuy/Desktop/Project/cantho-public-services/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-05 23:55:43.547235: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-05 23:55:43.547265: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: TranHuy-PC\n",
      "2024-05-05 23:55:43.547275: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: TranHuy-PC\n",
      "2024-05-05 23:55:43.547328: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.171.4\n",
      "2024-05-05 23:55:43.547349: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.171.4\n",
      "2024-05-05 23:55:43.547354: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.171.4\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-05-05 23:55:48.160316: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open rag/filter-model/model2/checkpoint/: FAILED_PRECONDITION: rag/filter-model/model2/checkpoint; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    }
   ],
   "source": [
    "from rag.modules.rag_facade import RAGFacade\n",
    "import json\n",
    "import time\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Cần làm gì để đăng ký kết hôn',\n",
       "  'context': ['Cần làm theo trình tự các bước sau để thực hiện thủ tục hành chính Thủ tục đăng ký kết hôn'],\n",
       "  'answer': 'Để đăng ký kết hôn, bạn cần làm theo các bước sau:\\n\\n1. Nộp hồ sơ tại Ủy ban nhân dân cấp xã có thẩm quyền.\\n2. Người tiếp nhận sẽ kiểm tra toàn bộ hồ sơ và đối chiếu thông tin trong Tờ khai và giấy tờ trong hồ sơ.\\n3. Nếu hồ sơ đầy đủ và hợp lệ, người tiếp nhận sẽ viết giấy tiếp nhận và trả kết quả. Nếu hồ sơ chưa đầy đủ, người nộp hồ sơ sẽ được hướng dẫn bổ sung hoặc hoàn thiện.\\n4. Hồ sơ sau khi được hướng dẫn mà không được bổ sung đầy đủ sẽ bị từ chối tiếp nhận.\\n5. Nếu hồ sơ đủ điều kiện, công chức tư pháp - hộ tịch sẽ báo cáo Chủ tịch Ủy ban nhân dân cấp xã. Nếu Chủ tịch đồng ý, sẽ tiến hành kết hôn và trao Giấy chứng nhận kết hôn.\\n\\nLưu ý: Giấy tờ nộp phải là bản sao được cấp từ sổ gốc hoặc bản sao được chứng thực từ bản chính. Người tiếp nhận không được yêu cầu xuất trình bản chính.'},\n",
       " {'question': 'Mang theo giấy tờ gì để đăng ký kết hôn',\n",
       "  'context': ['Cần các hồ sơ sau đây làm thủ tục hành chính Thủ tục đăng ký kết hôn và nộp tại địa điểm nơi sau'],\n",
       "  'answer': 'Để đăng ký kết hôn, bạn cần mang theo các giấy tờ sau:\\n1. Bản chính Giấy xác nhận tình trạng hôn nhân do Ủy ban nhân dân cấp xã có thẩm quyền cấp (nếu người yêu cầu đăng ký kết hôn không đăng ký thường trú tại địa bàn xã, phường, thị trấn).\\n2. Hộ chiếu hoặc Chứng minh nhân dân hoặc Thẻ căn cước công dân hoặc các giấy tờ khác có dán ảnh và thông tin cá nhân.\\n3. Trích lục ghi chú ly hôn (nếu có).\\n4. Tờ khai đăng ký kết hôn theo mẫu.\\n\\nNgoài ra, bạn cũng cần mang theo bản chụp các giấy tờ gửi kèm theo hồ sơ đăng ký kết hôn trực tuyến, bảo đảm rõ nét, đầy đủ, toàn vẹn về nội dung.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('rag/evaluation/test_answered.json') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_number(text):\n",
    "    numbers = re.search(r'\\d+', text)\n",
    "    answer = numbers.group(0)\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_precision(context: List[str], question: str):\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i, text in enumerate(context):\n",
    "        prompt += f\"===\\nNgữ cảnh {i}:\\n\" + text + \"\\n\\n\"\n",
    "    \n",
    "    prompt += \"Câu hỏi: \" + question\n",
    "    prompt +=\"\\n\\nSố ngữ cảnh liên quan câu hỏi: \"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Bạn là người đánh giá mức độ liên quan giữa các đoạn thông tin và câu hỏi. Hãy giúp đánh giá các đoạn thông tin sau đây.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Bên dưới sẽ là các đoạn thông tin ngữ cảnh và một câu hỏi. Hỏi có bao nhiêu ngữ cảnh có liên quan đến câu hỏi. Chỉ trả lời một số là số lượng ngữ cảnh liên quan, không thêm ký tự khác.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "    \n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    return retrieve_number(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_accuracy(truth_answer, answer):\n",
    "    prompt = f\"Đáp án đúng\\n: {truth_answer}\\n\\nCâu trả lời sinh ra từ chatbot\\n: {answer} \\n\\nĐộ chính xác:\"\n",
    "    completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Bạn là người đánh giá độ chính xác của câu trả lời từ chatbot về thủ tục hành chính.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Bên dưới sẽ là câu đáp án đúng và câu trả lời sinh ra từ chatbot. Hãy đánh giá độ chính xác của trả lời từ chatbot trên thang điểm từ 0 đến 100.\\nChỉ trả về một con số là độ chính xác của câu trả lời, KHÔNG thêm ký tự khác.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "    \n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    return retrieve_number(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate context recall \n",
    "truth_retrieved = 0\n",
    "truth_context_length = 0\n",
    "question_time = []\n",
    "\n",
    "# Context precision\n",
    "context_precisions = []\n",
    "\n",
    "# Answer accuracy\n",
    "answer_accuracies = []\n",
    "\n",
    "def calculate_metrics(question):\n",
    "    global truth_context_length\n",
    "    truth_context_length += len(question[\"context\"])\n",
    "\n",
    "    retrieved_response = RAGFacade.generate_response(question[\"question\"], eval=True)\n",
    "    context = retrieved_response[\"documents\"]\n",
    "    retrieved_context = [context.page_content for context in context]\n",
    "    question_time.append(retrieved_response[\"times\"])\n",
    "\n",
    "    # Calculate context recall\n",
    "    for truth_context in question[\"context\"]:\n",
    "        if truth_context in retrieved_context:\n",
    "            global truth_retrieved\n",
    "            truth_retrieved += 1\n",
    "\n",
    "    print(f\"Context Recall: {truth_retrieved / truth_context_length}\")\n",
    "    \n",
    "    \n",
    "    # Calculate context precision\n",
    "    try:\n",
    "        global context_precisions\n",
    "        context_pre =  context_precision(retrieved_context, question[\"question\"]) / len(retrieved_context)\n",
    "        context_precisions.append(context_pre)\n",
    "        print(f\"Context Precision: {context_pre}\")\n",
    "    except (Exception):\n",
    "        pass\n",
    "\n",
    "    # Calculate answer correctness\n",
    "\n",
    "    # try:\n",
    "    global answer_accuracies\n",
    "    accuracy = answer_accuracy(question[\"answer\"], retrieved_response[\"answer\"])\n",
    "    answer_accuracies.append(accuracy)\n",
    "    print(f\"Answer Accuracy: {accuracy}\")\n",
    "    # except (Exception):\n",
    "    #     pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Recall: 1.0\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 70\n",
      "Context Recall: 1.0\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 50\n",
      "Context Recall: 0.6666666666666666\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 65\n",
      "Context Recall: 0.75\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 85\n",
      "Context Recall: 0.8\n",
      "Context Precision: 1.0\n",
      "Answer Accuracy: 100\n",
      "Context Recall: 0.8333333333333334\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 95\n",
      "Context Recall: 0.8571428571428571\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 95\n",
      "Context Recall: 0.875\n",
      "Context Precision: 0.4\n",
      "Answer Accuracy: 85\n",
      "Context Recall: 0.8888888888888888\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 85\n",
      "Context Recall: 0.9\n",
      "Context Precision: 1.0\n",
      "Answer Accuracy: 95\n",
      "Context Recall: 0.9090909090909091\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 70\n",
      "Context Recall: 0.9166666666666666\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 95\n",
      "Context Recall: 0.9230769230769231\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 0\n",
      "Context Recall: 0.9285714285714286\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 95\n",
      "Context Recall: 0.8666666666666667\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 50\n",
      "Context Recall: 0.8125\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 0\n",
      "Context Recall: 0.7647058823529411\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 65\n",
      "Context Recall: 0.7222222222222222\n",
      "Context Precision: 0.4\n",
      "Answer Accuracy: 0\n",
      "Context Recall: 0.7368421052631579\n",
      "Context Precision: 0.4\n",
      "Answer Accuracy: 90\n",
      "Context Recall: 0.75\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 0\n",
      "Context Recall: 0.7142857142857143\n",
      "Context Precision: 0.0\n",
      "Answer Accuracy: 0\n",
      "Context Recall: 0.7272727272727273\n",
      "Context Precision: 0.4\n",
      "Answer Accuracy: 85\n",
      "Context Recall: 0.7391304347826086\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 100\n",
      "Context Recall: 0.7083333333333334\n",
      "Context Precision: 0.8\n",
      "Answer Accuracy: 85\n",
      "Context Recall: 0.68\n",
      "Context Precision: 0.0\n",
      "Answer Accuracy: 50\n",
      "Context Recall: 0.6923076923076923\n",
      "Context Precision: 0.6\n",
      "Answer Accuracy: 95\n"
     ]
    }
   ],
   "source": [
    "# Loop in batches of 10\n",
    "i = 0\n",
    "while i < len(data):\n",
    "    batch = data[i:min(i+10, len(data))]\n",
    "    for question in batch:\n",
    "        calculate_metrics(question)\n",
    "    i += 10\n",
    "    if i > len(data):\n",
    "        break\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_context_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Với K=5\n",
      "Context Recall: 0.6923076923076923\n",
      "Context precision: 0.630769230769231\n",
      "Answer accuracy: 65.57692307692308\n"
     ]
    }
   ],
   "source": [
    "print(\"Với K=5\")\n",
    "\n",
    "print(f\"Context Recall: {truth_retrieved / truth_context_length}\")\n",
    "print(f\"Context precision: {sum(context_precisions) / len(context_precisions)}\")\n",
    "print(f\"Answer accuracy: {sum(answer_accuracies) / len(answer_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"context_recall\": truth_retrieved / truth_context_length,\n",
    "    \"context_precision\": sum(context_precisions) / len(context_precisions),\n",
    "    \"answer_accuracy\": sum(answer_accuracies) / len(answer_accuracies),\n",
    "    \"times\": question_time\n",
    "}\n",
    "\n",
    "with open(\"rag/evaluation/@5/result.json\", \"w\", encoding='utf8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
